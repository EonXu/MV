{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, concatenate, GlobalAveragePooling2D, Dense, MaxPooling2D, Dropout, Flatten, ReLU, Add, BatchNormalization, AveragePooling2D, Multiply, GlobalAveragePooling2D, Reshape,DepthwiseConv2D\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from PIL import Image\n",
    "from tensorflow.keras.metrics import Metric,Precision, Recall\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNet\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'E:\\MV\\coursework\\fruits-360\\Training'\n",
    "test_dir = r'E:\\MV\\coursework\\fruits-360\\Test'\n",
    "#The total number of images: 90483.\n",
    "#Training set size: 67692 images (one fruit or vegetable per image).\n",
    "#Test set size: 22688 images (one fruit or vegetable per image).\n",
    "#The number of classes: 131 (fruits and vegetables).\n",
    "#Image size: 100x100 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfClass:  131\n"
     ]
    }
   ],
   "source": [
    "#find out the total calsses of dataset.\n",
    "className = glob.glob(train_dir + \"/*\")\n",
    "numberOfClass = len(className)\n",
    "print(\"NumberOfClass: \",numberOfClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_background(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "    thresh_rgb = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
    "    np.copyto(image, thresh_rgb, where=thresh_rgb == 255)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63145 images belonging to 131 classes.\n",
      "Found 4547 images belonging to 131 classes.\n",
      "Found 22688 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=denoise_background,\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.068,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    subset='training' \n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load and preprocess the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100,100),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Input(shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracy(Metric):\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super(CustomAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.correct = self.add_weight(name='correct', initializer='zeros')\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "        y_true_classes = tf.argmax(y_true, axis=1)\n",
    "        correct_predictions = tf.equal(y_pred_classes, y_true_classes)\n",
    "        correct_predictions = tf.cast(correct_predictions, 'float32')\n",
    "        \n",
    "        self.correct.assign_add(tf.reduce_sum(correct_predictions))\n",
    "        self.total.assign_add(tf.cast(tf.size(y_true_classes), 'float32'))\n",
    "\n",
    "    def result(self):\n",
    "        return tf.divide(self.correct, self.total)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.correct.assign(0)\n",
    "        self.total.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCrossEntropyLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name='loss', **kwargs):\n",
    "        super(CustomCrossEntropyLoss, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        epsilon = 1e-10\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the output layer for the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model):\n",
    "    x = Dense(128, activation='relu')(base_model.output) \n",
    "    x = BatchNormalization()(x) \n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x) \n",
    "    x = Dropout(0.3)(x)\n",
    "    last_output= Dense(numberOfClass, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=last_output)\n",
    "    return model \n",
    "\n",
    "def prepare_model(model):\n",
    "    model = add_new_last_layer(model)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss=CustomCrossEntropyLoss(),metrics=[CustomAccuracy(), Precision(name='precision'),Recall(name='recall')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = prepare_model(VGG16(weights=None, include_top=False, input_shape=(100,100,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the vgg16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1974/1974 [==============================] - 436s 221ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 2/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 3/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 4/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 5/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 6/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 7/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 8/40\n",
      "1974/1974 [==============================] - 352s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 9/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 10/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 11/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 12/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 13/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 14/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 15/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 16/40\n",
      "1974/1974 [==============================] - 354s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 17/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 18/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 19/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 20/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 21/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 22/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 23/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 24/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 25/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 26/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8592 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 27/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 28/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 29/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8592 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 30/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 31/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 32/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 33/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 34/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 35/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 36/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 37/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 38/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 39/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n",
      "Epoch 40/40\n",
      "1974/1974 [==============================] - 353s 179ms/step - loss: 22.8593 - accuracy: 0.0072 - precision: 0.0072 - recall: 0.0072 - val_loss: 22.8588 - val_accuracy: 0.0073 - val_precision: 0.0073 - val_recall: 0.0073\n"
     ]
    }
   ],
   "source": [
    "history_vgg16=vgg16_model.fit(train_generator, epochs=40, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the history of vgg16\n",
    "\n",
    "save_history_vgg16 = pd.DataFrame(history_vgg16.history)\n",
    "\n",
    "save_history_vgg16.to_csv(\"vgg16_model_training_history_40epoch_1213.csv\", index=False)\n",
    "\n",
    "save_path=r'vgg16_model1213_40epochs.h5'\n",
    "vgg16_model.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
